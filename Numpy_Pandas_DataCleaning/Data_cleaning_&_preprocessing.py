# -*- coding: utf-8 -*-
"""2.3 Data Cleaning & Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t-7e7YC4wPkvi72TmBBsEhC5FlV2nw5Y
"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/fcai-summer-training/Session 2/boat_data_manipulated.csv')
df.head()

"""# Cleaning and preprocessing

## Checking data type correctness
"""

df.info()

"""**Amount and year_built should be parsed and turned into int64**

How can we do that?

### solution
"""

df['amount'] = df['amount'].apply(lambda x: float(x[:-1]))

df['year_built'] = df['year_built'].apply(lambda x: x if type(x) != type('') else int(x.replace('in ', '')))

df.info()

"""## Checking duplicates"""

df.duplicated().sum()

"""**There are 120 duplicated rows in this dataset**

should we remove them?

### Solution
"""

df = df.drop_duplicates()

df.duplicated().sum()

"""## Checking Missing Data"""

df.isna().sum()

"""There are multiple values that are null and there are two ways to handle them, one is to impute them and the other is to drop them; but how to choose between them?

1. Dropping Data
> - dropping **rows** where there are null values than threshold
> - dropping **columns** where there are null values than threshold

2. Imputing Data
> - numerical data can be imputed using mean, median or even mode
> - categorical data can be imputed using mode
**NOTE THAT**: both numerical and categorical data can be imputed using **KNN imputing** algorithm but this is an advanced topic and left for self-study

### Dropping data
Always make sure that the data you're dropping is as small as possible as to not lose important information

#### Checking null values row wise
"""

rows = df.isna().sum(axis=1)
print('we have ', rows[rows >= 4].shape[0], ' rows that contian more than 4 null values')
rows[rows >= 4]

idexes_to_drop = rows[rows >= 3].index
df = df.drop(index=idexes_to_drop)

df.isna().sum()

"""#### Checking null values row wise

**Let's assume we have a threshold of 30%> to drop the whole column**
"""

np.round((df.isna().sum()/df.shape[0])*100)

"""**these columns should not be dropped since they are less than 30% empty**

### Imputing data

#### 1. Handling numric

##### 1.1 replacing with mean
"""

df[(df['width'].isna()) | (df['length'].isna())].head()

df = df.fillna({
    'width': df['width'].mean(),
    'length':df['width'].mean()
})

df[(df['width'].isna()) | (df['length'].isna())].head()

"""##### 1.2 replacing with median"""

df[df['year_built'].isna()].head()

df = df.fillna({
    'year_built': df['year_built'].median(),
})

df[df['year_built'].isna()].head()

"""#### 2. Handling categorical

##### 1.1 replacing with mode
"""

mask =  df['type'].isna() | df['manufacturer'].isna() | df['material'].isna() | df['location'].isna() | df['iso'].isna()
df[mask].head()

df = df.fillna({
    'type': df['type'].mode()[0],
    'manufacturer': df['manufacturer'].mode()[0],
    'material': df['material'].mode()[0],
    'location': df['location'].mode()[0],
    'iso': df['iso'].mode()[0],
})

df[df['type'].isna()].head()

"""##### 1.2 using KNNImputer (Self-Study)"""



"""### output after cleaning"""

df.isna().sum()

"""## Checking outliers

**Checking outliers can be either upfront or tricky since you need to define what could be considered an outlier for your data**

### describing data

first you need to have a statistical view/analysis of your data:
this can be done with Dataframe `.describe()` method
"""

df.describe()

"""in `amount` column we can see that the minimum value for an amount is $3,300$ and max is $31,000,000$ with a mean of $317,313.1$ and std of $997,140.3$

**What can we conclude from that?**

there is a serious case of outliers in this column

### plotting data

We can also plot the distribution of the data in a **histogram** or a **box plot**
"""

import seaborn as sns
import matplotlib.pyplot as plt

"""#### Boxplots"""

sns.boxplot(data=df, x='amount')
plt.show()

"""#### Histograms"""

sns.histplot(data=df, x='amount')
plt.show()

"""#### life hack to make all our lives easier"""

cols = ['amount', 'year_built', 'length', 'width']
for col in cols:
    sns.boxplot(data=df, x=col)
    plt.show()

cols = ['amount', 'year_built', 'length', 'width']
for col in cols:
    sns.histplot(data=df, x=col)
    plt.show()

"""### Conclusion after plotting

now what we did is that we supported our assumption that amount may have outliers

**how can we handle them then?**

#### Using quartiles
"""

q75, q25 = np.percentile(df.loc[:, 'amount'], [75, 25])
intr_qr = q75 - q25

max = q75 + (1.5 * intr_qr)
min = q25 - (1.5 * intr_qr)

print('lower bound is = %0.2f and higher bound is = %0.2f for amount' %(min, max))

quartiles_df = df.copy()
quartiles_df.loc[quartiles_df['amount'] < min, 'amount'] = np.nan
quartiles_df.loc[quartiles_df['amount'] > max, 'amount'] = np.nan

quartiles_df.isna().sum()

quartiles_df = quartiles_df.dropna()

sns.boxplot(data=quartiles_df, x='amount')

sns.histplot(data=quartiles_df, x='amount')

quartiles_df.describe()

"""#### using Z-score (normal-distribution)"""

from scipy import stats

z = np.abs(stats.zscore(df['amount']))


z_df = df.copy()

threshold = 3 #standard cutoff value
z_df.loc[z > threshold, 'amount'] = None

z_df.isna().sum()

z_df = z_df.dropna()

sns.boxplot(data=z_df, x='amount')

sns.histplot(data=z_df, x='amount')

z_df.describe()

"""#### outlier reomval depends on the buissness problem and buissness knowledge

# Refrences
[5 Ways to Find Outliers in Your Data](https://statisticsbyjim.com/basics/outliers/)

[Ways to Detect and Remove the Outliers](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba)

[Handling outliers in python](https://careerfoundry.com/en/blog/data-analytics/how-to-find-outliers/)
"""